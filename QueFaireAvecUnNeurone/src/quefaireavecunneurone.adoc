Que faire avec un neurone ?
===========================
Collonville Thomas                                     
Version 0.1.0-SNAPSHOT, 20/11/2018                                             

:sectnums:                                                          
:toc:                                                               
:toclevels: 4                                                       
:toc-title: Plan                                              
:description: Document de presentation du neurone                              
:keywords: Neurone IA Machine learning python                                                 
:imagesdir: ./img                                                   

[quote, Robert Heinlein]
When one teach, two learn

[TIP]
Ou un peu d'espoir pour certains d'entre nous...

Sommaire
--------
* Qu'est ce que l'IA
* Historique
* Le neurone 
* Processus de traitement
* Exemple 


Qu'est ce que l'IA
------------------

image::IAdecoupe.png[800,600]

Historique
----------

* 1940 : Alan TURING : Machine de Turing
* 1943 : Warren McCULLOCH & Walter PITTS Modèle formel de neurone.
* 1949 : Donald HEBB : Mémoire associative, premières règles d'apprentissage.
* 1960 : Franck ROSENBLATT et Bernard WIDROW, Perceptron et Adaline.
* 1980 : Stephen GROSSBERG et Teuvo KOHONEN Auto-organisation des réseaux et adaptation

Historique
~~~~~~~~~~
* 1986 : Paul Smolenski : Machine de BOLTZMANN 
* 1997: Deep Blue
* 2011 : Watson
* 2014 : LeCun Deep Learning 
* 2015 : Alpha Go
* 2018 : Alexa

Les modeles
-----------

Non-supervisé
~~~~~~~~~~~~~

* Foret aléatoire 
* Clustering et réduction de dimension 
* SVD 
* Analyse par composante principale
* Règles

Supervisé
~~~~~~~~~

* Régression linéaire ou logistique 
* Descente de gradient  
* Régression polynomiale 
* Séparation a vaste marge (SVM) 
* Arbre de descision 
* Classification linéaire ou non linéaire 
* Réseau de neurone 
* Naïve bayes

Le neurone 
----------

* Outil mathématique 
* Formalisé par McCULLOCH et PITTS

Le neurone biologique
~~~~~~~~~~~~~~~~~~~~~

image::Neurone.png[800,600]

Constitution
~~~~~~~~~~~~

* d'un noyau : le cœur de la cellule neuronale
* de dendrites permettant d’agréger les informations entrantes venant des synapses
* d'axones fournissant la réponse neuronale
* de synapses : interconnexion entre les axones et les dendrites permettant le transfert de l’influx nerveux 

Quelques nombres
~~~~~~~~~~~~~~~~

* 100 Milliards de neurones
* 10000 Synapses par neurone 
* 10^15 Synapses dans le cerveau humain

Utilité
~~~~~~~

* Mémoire et persistance des données dans le temps
* Réflexion, élaboration des idées, associer des concepts et des stratégies 
* Sens, Analyse des données, traitements des sons, des images, du touché
* Construction d'une réponse moteur, l’équilibre, l'orientation, la marche, dextérité

Le neurone formel
~~~~~~~~~~~~~~~~~
image::modeleMathNeurone.png[]
image::modeleMatriciel.png[]

* a la sortie du neurone
* xi, le signal d'entré 
* wi, le poid de ponderation 
* biais, une constante de pondération 
* f, la fonction d’activation 

Le neurone formel
~~~~~~~~~~~~~~~~~

image::ModeleNeurone.png[800,600]

La fonction d'activation
~~~~~~~~~~~~~~~~~~~~~~~~

Lineaire
~~~~~~~~

image::lineaire.png[800,600]

Sigmoire
~~~~~~~~

image::sigmoide.png[800,600]

Limiteur
~~~~~~~~

image::limiteur.png[800,600]

Processus
---------

* Analyse du probleme
** Nettoyage des données
** Visualisation des données
** Jeux de test
** Jeux d'entrainement
* Definition d'un modele
* Apprentissage
* Mesure d'efficacité 
* Mise en exploitation

Exemples
--------

* Problemes de classification
* Approche Linéaire
* Approche Sigmoide
* Probleme de regression
* Approche Linéaire


Probleme de tri
---------------

image::ProblemeClassification.png[]
* a rugosité -> 0 lisse a 1 rugeux
* la couleur -> 0 bleu a 1 rouge
* la forme -> 0 rond a 1 alongé
* le poid -> 0 (20gr) à 1 (2000gr)

Les données
~~~~~~~~~~~

[source,python]
---------------
def generateSet(prototype,nbrEchantillon,coef):
    rand_value=np.random.randn(len(prototype),len(prototype[0]))/coef
    #print(rand_value)
    rand_set=prototype+rand_value
    if nbrEchantillon == 0 :
        return prototype
    else:
        return np.concatenate((rand_set,generateSet(prototype,nbrEchantillon-1,coef)))
---------------

Les données
~~~~~~~~~~~
[source,python]
---------------
pasteque=np.array([[0.2, 0.3, 0.2, 0.95]])
anana=np.array([[0.8, 0.65, 0.6, 0.8]])

pasteques=generateSet(pasteque,1999,10)
ananas=generateSet(anana,1999,10)
# 10 -> pour separer les ensembles
---------------

Les données
~~~~~~~~~~~

image::donnePastequeAnana.png[800,600]

Profil moyen
~~~~~~~~~~~~

 pastèque [0.2, 0.3, 0.2, 0.95] 
 anana [0.8, 0.65, 0.6, 0.8] 

La classification lineaire
--------------------------

Solution adhoc
~~~~~~~~~~~~~~

* W=[1;1;1;0]
* biais 1,5

* Verification analytique
** limiteur((Wt.pasteque)-biais)= limiteur( 0.4- 1.5)= limiteur(-1.1 )= 0
** limiteur((Wt.anana)-biais)= limiteur( 2.35- 1.5)= limiteur(0.85 )= 1

Pourquoi ca marche
~~~~~~~~~~~~~~~~~~

image::setWithVect.png[800,600]

Solution logicielle
~~~~~~~~~~~~~~~~~~~

[source,python]
---------------
def neuroneLim(entre,W,biais):
    a=np.dot(entre,W.T)-biais
    #print("a neurone:",a)
    if a > 0:
        return 1
    return 0
---------------

Mesure de la performance
~~~~~~~~~~~~~~~~~~~~~~~~

* Calcul du cout
** Ratio des bonnes reponses par rapport au mauvaise

* (2 echantillons de 2000 anana et 2000 pasteques)
* pas de pasteques: 71  
** taux de reussite : 96.49824912456228
* qui sont des ananas: 1815 
** taux de reussite : 90.79539769884943


Superposition
~~~~~~~~~~~~~

image::donnePastequeAnanaNonSepare.png[800,600]

Outil plus precis?

Matrice de confusion
~~~~~~~~~~~~~~~~~~~~

image::matConf.png[]

Interpretation
~~~~~~~~~~~~~~

* (jeux de données de 4000 elements)
* 1938 Vrai Positif 
* 1798 Vrai Négatif 
* 62 Faux Négatif 
* 202 Faux Positif 

Precision et rappel
~~~~~~~~~~~~~~~~~~~

* Précision : VP/(VP+FP)= 1938/(1938+202) = 0.90 
** capacité à détecter des pastèques en présence d’ananas 
** 0.90 de chance que le modèle réponde que le fruit est un ananas
* Rappel ou sensibilité : VP/(VP+FN)= 1938/(1938+62) =0.97 
** capacité à réellement détecter une pastèque dans un ensemble ne contenant que de pastèques

Apprentissage
~~~~~~~~~~~~~

* supervisés -> on indique la bonne reponse
* non supervisé -> le modele interprete la reponse (approche par clustering)
* semi-supervisé

* si etiquete - sortie > 0 alors W=W+data 
* si etiquete - sortie < 0 alors W=W-data
* si etiquete - sortie = 0 alors W

Apprentissage
~~~~~~~~~~~~~

[source,python]
---------------
def majW(W, sortie, etiquette,entree):
    return W+(etiquette-sortie)*entree

for (val,etiquete) in datasApprentissage:
    sortie=neuroneLim(val,W,biais)
    W=majW(W, sortie, etiquete,val)
---------------

Test de l'apprentissage
~~~~~~~~~~~~~~~~~~~~~~~

[source,python]
---------------
for (val,etiquete) in datasTest:
    sortie=neuroneLim(val,W,biais)
    #print(sortie,etiquete)
    if sortie != etiquete:
        erreur.append(erreur[len(erreur)-1]+1)
    else:
        erreur.append(erreur[len(erreur)-1])
---------------

Test de l'apprentissage
~~~~~~~~~~~~~~~~~~~~~~~

image::tauxerreru.png[800,600]

La classification sigmoide
--------------------------

Modele Sigmoide
~~~~~~~~~~~~~~~

[source,python]
---------------
def neuroneCore(entre,W,biais):
    return np.dot(entre,W.T)-biais

def sigmoid(a):
    return 1 / (1 + math.exp(-a))
    
def neuroneSig(entre,W,biais):
    a=neuroneCore(entre,W,biais)
    return sigmoid(a)
---------------

Resultat
~~~~~~~~

* (jeux de données de 1000 elements)
* 15 données indécidables
* 471 pasteques qui sont bien des pasquetes!
* 452 ananas qui sont bien des ananas!
* risque alpha erreur ou erreur de premiere espece
** 22 ananas qui se prennent pour des pastèques 
* risque beta erreur ou erreur de seconde espece
** 40 pasteques qui se prennent pour des ananas


Interpretation
~~~~~~~~~~~~~~

image::datasSig.png[800,600]

La regression lineaire
----------------------

Problematique
~~~~~~~~~~~~~

image::donneesBruite.png[800,600]

Estimateur
~~~~~~~~~~

image::estimateurLineaire.png[]

 Equation Normale

image::equationNormale.png[]

Inference
~~~~~~~~~

[source,java]
---------------
public Double linearInfer(Double[] stepInputs)
{
    Stream.Builder<Double> sum=Stream.<Double>builder();
    for(int i=0;i<dendrites.length;i++)
    {
        if(i<stepInputs.length)
            sum.add(dendrites[i]*stepInputs[i]);
        else
            sum.add(dendrites[i]);
    }
    return sum.build().reduce((x,y)-> x+y).get();;
}
---------------

Performance
~~~~~~~~~~~

* MSE : Mean Square Error
* RMSE: Root Mean Square Error

image::MSE.png[]

* MAE : Mean Absolute Error

image::MAE.png[]

Apprentissage
~~~~~~~~~~~~~

* Descente de gradient

Conclusion
----------

* Un neurone ne fait pas un cerveau
 
 mais

* On a besoin d'un cerveau pour comprendre le neurone







